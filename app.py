import os
import sys
import streamlit as st
import openai
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader
from langchain.memory import ConversationSummaryMemory
from langchain.vectorstores import FAISS


openai.api_key = os.environ["OPENAI_API_KEY"] or st.secrets.openai_key
FIRST_AI_MESSAGE = '–°–ø–∏—Ç–∞–π—Å—è –º–µ–Ω–µ —â–æ –∑–∞–≤–≥–æ–¥–Ω–æ –ø–æ –ë—ñ–±–ª—ñ—ó'


st.set_page_config(
    page_title="–ü–∏—Ç–∞–Ω–Ω—è –ø–æ –ë—ñ–±–ª—ñ—ó",
    page_icon="ü§≤",
    layout='centered',
    initial_sidebar_state="auto",
    menu_items=None)


if "messages" not in st.session_state.keys():
    st.session_state.messages = [
        {"role": "assistant", "content": FIRST_AI_MESSAGE}
    ]


def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": FIRST_AI_MESSAGE}
    ]


with st.sidebar:
    st.info('–¶–µ —á–∞—Ç–±–æ—Ç, —è–∫–∏–π –º–∞—î –¥–æ—Å—Ç—É–ø –¥–æ –≤—Å—å–æ–≥–æ —Ç–µ–∫—Å—Ç—É –ë—ñ–±–ª—ñ—ó —Ç–∞ –º–æ–∂–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è.', icon="‚ÑπÔ∏è")
    st.write("–¶—é –¥–µ–º–∫—É —Å—Ç–≤–æ—Ä–∏–≤ [–¢–∞—Ä–∞—Å –°–≤–∏—Å—Ç—É–Ω](https://github.com/taras-svystun).")
    st.write('–ü–æ–≥–ª—è–Ω—É—Ç–∏ –Ω–∞ –∫–æ–¥ –∑–∞—Å—Ç–æ—Å—É–Ω–∫—É –º–æ–∂–Ω–∞ [—Ç—É—Ç](https://github.com/taras-svystun/ukr-bible-qa-chatbot).')
    st.write("–¢–µ–∫—Å—Ç –ë—ñ–±–ª—ñ—ó –≤ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–º—É –ø–µ—Ä–µ–∫–ª–∞–¥—ñ –±—É–ª–æ –≤–∑—è—Ç–æ [–∑–≤—ñ–¥—Å–∏](https://www.jw.org/uk/–±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞/–±—ñ–±–ª—ñ—è/nwt/–∫–Ω–∏–≥–∏/).")
    st.button(":red[–°—Ç–µ—Ä—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é —á–∞—Ç—É]", on_click=clear_chat_history)


st.title("–í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è –ø–æ –ë—ñ–±–ª—ñ—óüëº")


@st.cache_resource(show_spinner=False)
def load_data():
    with st.spinner(text="Loading..."):
        loader = TextLoader("bible.txt")
        documents = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1150, chunk_overlap=150, length_function = len,
                                                       separators=[" ", ",", "\n"]
                                                       )
        text_chunks = text_splitter.split_documents(documents)
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.from_documents(text_chunks, embeddings)
        return vectorstore.as_retriever()
        

retriever = load_data()


if "chat_engine" not in st.session_state.keys():
    llm = ChatOpenAI(temperature=.2)
    memory = ConversationSummaryMemory(
        llm=llm, memory_key="chat_history", return_messages=True
    )
    qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)
    st.session_state['chat_engine'] = qa


if prompt := st.chat_input("Your question"):
    st.session_state.messages.append({"role": "user", "content": prompt})


for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])


if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("–î–∞–π –ø–æ–¥—É–º–∞—é...ü§î"):
            response = st.session_state.chat_engine(prompt)
            st.write(response['answer'])
            message = {"role": "assistant", "content": response['answer']}
            st.session_state.messages.append(message)